- Explanation for sleep_pattern_dataset :-
In the current project, I will de-brief a dataset with Python and pandas. My initial step was to eliminate all the missing and duplicate records to have a consistent data. Subsequently, I normalized the column names writing them into lowercase characters, and thus having spaces changed into underscores, so they could be utilized in the analysis and SQL database activities far more proficiently. Numeric values (that was coded in the gender and university_year columns) helped in modeling. I also rounded continuous numeric variables e.g., time spent on sleep, time spent on studying and on screens to one decimal place as well. As the last step, the cleaned and normalized data was written out as a new CSV file to be used in further analysis.

-Implementation of data cleaning  of student_insomnia_dataset:
In order to clean up the student insomnia data we renamed the column names to something useful to work with and excluded the Timestamp column that is not very useful in analysis process. Then, we applied regular expression to delete additional information in categorical answers for e.g.: description in brackets and leave only the main labels such as “Often” or “Rarely”. Then, depending on the answers, we changed corresponding columns to ordered categorical types to maintain the logical order of answers. Values that were missing were also replaced with the respective column mode in order to be consistent with the rest of the data. Lastly, we stored the de-duplicated dataset as a new CSV, which would be analyzed.
